lungrads_pipeline:
  dependency_tree:
    - [csv_output, brat_postproc]
    - [brat_postproc, meta]
    - [brat_postproc, brat]
    - [brat_postproc, brat_re]
    - [brat_postproc, brat_neg]
    - [brat_re,tsv]
    - [brat_neg,tsv]
    - [tsv,brat]
    - [tsv,bio_init]
    - [tsv,encoded_text]
    - [brat,bio_init]
    - [brat,encoded_text]
    - [bio_init, encoded_text]
    - [bio_init, raw_text]
    - [encoded_text, raw_text]
  # root_dir: /data/datasets/shared_data_2/IRB201901754_lungrads
  root_dir: /data/datasets/shared_data_2/pipeline_dev_test
  raw_data_dir: /data/datasets/shared_data_2/pipeline_dev_test/raw_text/
  # TODO: specify model parameters here
  sent_tokenizer:
    _class: SentenceBoundaryDetection
    params:
      deid_pattern: \[\*\*|\*\*\]
  ner_model:
    _class:
    params:
        model_type: roberta
        pretrained_model: /home/jameshuang/Projects/NLP_annotation/fine_tuned_ner/mimiciii_roberta-base_10e_128b_bz=8
        do_lower_case: True
        eval_batch_size: 8
        max_seq_length: 128
        data_has_offset_information: True
        use_bio: False
  negation_model:
    _class:
    params:
        type: bert-base
        path:
  relation_model:
    _class:
    params:
        type: 
        path: /home/
  
