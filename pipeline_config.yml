lungrads_ner_training: # Generate bio from brat
  dependency_tree:
    - [bio, bio_init]
    - [bio, brat]
    - [brat,bio_init]
    - [brat,encoded_text]
    - [bio_init, encoded_text]
    - [bio_init, raw_text]
    - [encoded_text, raw_text]
  raw_data_dir: /home/jameshuang/Projects/lungrads/ner_training/datasets/training/encoded_text
  root_dir: /home/jameshuang/Projects/lungrads/ner_training/datasets/training

  sent_tokenizer:
    _class: SentenceBoundaryDetection
    params:
      deid_pattern: \[\*\*|\*\*\]

lungrads_ner_test: # Generate bio from brat
  dependency_tree:
    - [bio, bio_init]
    - [bio, brat]
    - [brat,bio_init]
    - [brat,encoded_text]
    - [bio_init, encoded_text]
    - [bio_init, raw_text]
    - [encoded_text, raw_text]
  raw_data_dir: /home/jameshuang/Projects/lungrads/ner_training/datasets/test/encoded_text
  root_dir: /home/jameshuang/Projects/lungrads/ner_training/datasets/test

  sent_tokenizer:
    _class: SentenceBoundaryDetection
    params:
      deid_pattern: \[\*\*|\*\*\]

lungrads_pipeline:
  dependency_tree:
    - [csv_output_lungrads, brat]
    - [csv_output_lungrads, brat_re]
    - [csv_output_lungrads, brat_neg]
    - [csv_output_lungrads, brat_unit]
    - [csv_output_lungrads, encoded_text]
    - [brat_unit, encoded_text]
    - [brat_unit, brat]
    - [brat_re,tsv]
    - [brat_neg,tsv]
    - [tsv,brat]
    - [tsv,bio_init]
    - [tsv,encoded_text]
    - [brat,bio_init]
    - [brat,encoded_text]
    - [bio_init, encoded_text]
    - [bio_init, raw_text]
    - [encoded_text, raw_text]
  # root_dir: /data/datasets/shared_data_2/IRB201901754_lungrads
  # root_dir: /data/datasets/shared_data_2/pipeline_dev_test
  # raw_data_dir: /data/datasets/shared_data_2/pipeline_dev_test/raw_text/
  root_dir: /data/datasets/shared_data_2/2022_IRB201901754_LDCT_IDR_data/radiology_reports/
  raw_data_dir: /data/datasets/shared_data_2/2022_IRB201901754_LDCT_IDR_data/radiology_reports/raw_text/
  # TODO: specify model parameters here

  sent_tokenizer:
    _class: SentenceBoundaryDetection
    params:
      deid_pattern: \[\*\*|\*\*\]

  ner_model:
    _class:
    params:
      model_type: roberta
      pretrained_model: /home/jameshuang/Projects/NLP_annotation/fine_tuned_ner/mimiciii_roberta-base_10e_128b_bz=8
      do_lower_case: True
      eval_batch_size: 8
      max_seq_length: 128
      data_has_offset_information: True
      use_bio: False
        
  relation_model:
    _class:
    preprocess:
      CUTOFF: 1
      EN1_START: "[s1]"
      EN1_END: "[e1]"
      EN2_START: "[s2]"
      EN2_END: "[e2]"
      NEG_REL: NonRel
      valid_comb: # TODO: load this from type_map
        - [nodule, texture]
        - [nodule, size]
        - [nodule, laterality]
        - [nodule, site]
        - [nodule, course]
        - [nodule, shape]  
    params:
      model_type: albert
      new_model_dir: /data/datasets/alexgre/from_wu_server/experiements/2020_lungrads/relation_extraction/models/RE_bin_albert_albert-base-v2_aio_cs2_0_th1_5_4
      do_lower_case: True
      eval_batch_size: 128
      max_seq_length: 512
      data_format_mode: 0
      data_file_header: True
      num_core: 16
      non_relation_label: NonRel
      classification_mode: bin
      type_map: /data/datasets/alexgre/from_wu_server/experiements/2020_lungrads/re_all/mappings.pkl
      log_lvl: w

  negation_model:
    _class:
    preprocess:
      entity_label: nodule
      EN1_START: "[s]"
      EN1_END: "[e]"
      NEG_REL: not-negated
    postprocess:
      keep_cat: [negated]
    params:
      model_type: bert
      new_model_dir: /home/jameshuang/Projects/NLP_annotation/fine_tuned_negation/mimiciii_bert-base-uncased_10e_128b/lr_1e-4_max_seq_length_256_batch_size_4/model
      do_lower_case: True
      eval_batch_size: 4
      max_seq_length: 256
      data_format_mode: 0
      data_file_header: True
      num_core: 16
      non_relation_label: NonRel
      classification_scheme: 1
      do_predict: True
      seed: 13
      log_lvl: i

  unit_extraction_model:
    _class:
    postprocess:
      normalize: mm

  csv_output_params:
    force_rewrite: True # remove old csv if True
    ouput_file: output.csv