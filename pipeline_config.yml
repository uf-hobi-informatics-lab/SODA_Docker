lungrads_ner_training: # Generate bio from raw_text + brat
  dependency_tree:
    - [bio, bio_init]
    - [bio, brat]
    - [brat,bio_init]
    - [brat,encoded_text]
    - [bio_init, encoded_text]
    - [bio_init, raw_text]
    - [encoded_text, raw_text]
  raw_data_dir: /home/jameshuang/Projects/lungrads/ner_training/datasets/training/encoded_text
  root_dir: /home/jameshuang/Projects/lungrads/ner_training/datasets/training

  sent_tokenizer:
    _class: SentenceBoundaryDetection
    params:
      deid_pattern: \[\*\*|\*\*\]

lungrads_ner_test: # Generate bio from raw_text + brat
  dependency_tree:
    - [bio, bio_init]
    - [bio, brat]
    - [brat,bio_init]
    - [brat,encoded_text]
    - [bio_init, encoded_text]
    - [bio_init, raw_text]
    - [encoded_text, raw_text]
  raw_data_dir: /home/jameshuang/Projects/lungrads/ner_training/datasets/test/encoded_text
  root_dir: /home/jameshuang/Projects/lungrads/ner_training/datasets/test

  sent_tokenizer:
    _class: SentenceBoundaryDetection
    params:
      deid_pattern: \[\*\*|\*\*\]

sdoh_pipeline: # Generate csv output from rawtext
  pipeline: sdoh
  dependency_tree:
    - [csv_output, brat]
    - [csv_output, brat_re]
    - [csv_output, encoded_text]
    - [brat_re,tsv]
    - [tsv,brat]
    - [tsv,bio_init]
    - [tsv,encoded_text]
    - [brat,bio_init]
    - [brat,encoded_text]
    - [bio_init, encoded_text]
    - [bio_init, raw_text]
    - [encoded_text, raw_text]
  root_dir: /data2/datasets/jameshuang/SDoH/sankalp/data/               # output directory
  raw_data_dir: /data2/datasets/jameshuang/SDoH/sankalp/data/raw_text/  # raw text directory

  sent_tokenizer:                                                       # tokenizer config
    _class: SentenceBoundaryDetection
    params:
      deid_pattern: \[\*\*|\*\*\]

  ner_model:                                                            # ner model config
    _class: Transformer
    # _class: TransformerMRC
    params:
      model_type: bert
      pretrained_model: /data/datasets/zehao/sdoh/model/SDOH_bert_final
      do_lower_case: None
      eval_batch_size: 8
      max_seq_length: 512
      data_has_offset_information: None
      use_bio: False

  relation_model:                                                       # rel model config
    _class:
    preprocess:
      CUTOFF: 1
      EN1_START: "[s1]"
      EN1_END: "[e1]"
      EN2_START: "[s2]"
      EN2_END: "[e2]"
      NEG_REL: NonRel
      valid_comb: # TODO: load this from type_map
        - [Tobacco_use, Substance_use_status] 
        - [Substance_use_status, Smoking_type]
        - [Substance_use_status, Smoking_freq_ppd] 
        - [Substance_use_status, Smoking_freq_py] 
        - [Substance_use_status, Smoking_freq_qy] 
        - [Substance_use_status, Smoking_freq_sy]
        - [Substance_use_status, Smoking_freq_other] 
        - [Alcohol_use, Substance_use_status]
        - [Substance_use_status, Alcohol_freq] 
        - [Substance_use_status, Alcohol_type] 
        - [Substance_use_status, Alcohol_other] 
        - [Drug_use, Substance_use_status]
        - [Substance_use_status, Drug_freq] 
        - [Substance_use_status, Drug_type]
        - [Substance_use_status, Drug_other] 
        - [Sex_act, Sdoh_status]
        - [Sex_act, Partner] 
        - [Sex_act, Protection] 
        - [Sex_act, Sex_act_other] 
        - [Occupation, Employment_status]
        - [Occupation, Employment_location] 
        - [Gender, Sdoh_status]
        - [Social_cohesion, Social_method] 
        - [Social_method, Sdoh_status]
        - [Physical_act, Sdoh_status] 
        - [Physical_act, Sdoh_freq] 
        - [Living_supply, Sdoh_status] 
        - [Abuse, Sdoh_status]
        - [Transportation, Sdoh_status] 
        - [Health_literacy, Sdoh_status]
        - [Financial_constrain, Sdoh_status] 
        - [Social_cohesion, Sdoh_status]
        - [Social_cohesion, Sdoh_freq] 
        - [Gender, Sdoh_status] 
        - [Race, Sdoh_status] 
        - [Ethnicity, Sdoh_status]
        - [Living_Condition, Sdoh_status]
    params:
      model_type: bert
      new_model_dir: /data/datasets/zehao/sdoh/relations_model/bert
      do_lower_case: True
      eval_batch_size: 4
      max_seq_length: 512
      data_format_mode: 0
      data_file_header: True
      num_core: 1
      non_relation_label: NonRel
      classification_mode: bin
      log_lvl: w

  csv_output_params:                                                  # csv_output config
    force_rewrite: True # remove old csv if True
    ouput_file: output.csv


sdoh_pipeline_docker:
  pipeline: sdoh
  dependency_tree:
    - [csv_output, brat]
    - [csv_output, brat_re]
    - [csv_output, encoded_text]
    - [brat_re,tsv]
    - [tsv,brat]
    - [tsv,bio_init]
    - [tsv,encoded_text]
    - [brat,bio_init]
    - [brat,encoded_text]
    - [bio_init, encoded_text]
    - [bio_init, raw_text]
    - [encoded_text, raw_text]
  root_dir: /data/datasets/shared_data_2/pipeline_dev_test_sdoh
  raw_data_dir: /data/datasets/shared_data_2/pipeline_dev_test_sdoh/raw_text/

  sent_tokenizer:
    _class: SentenceBoundaryDetection
    params:
      deid_pattern: \[\*\*|\*\*\]

  ner_model:
    _class:
    params:
      model_type: bert
      # pretrained_model: /home/dparedespardo/project/SDoH/pipeline/execution/model/SDOH_bert_final
      pretrained_model: /models/SDOH_bert_final
      do_lower_case: None
      eval_batch_size: 8
      max_seq_length: 128
      data_has_offset_information: None
      use_bio: False

  relation_model:
    _class:
    preprocess:
      CUTOFF: 1
      EN1_START: "[s1]"
      EN1_END: "[e1]"
      EN2_START: "[s2]"
      EN2_END: "[e2]"
      NEG_REL: NonRel
      valid_comb: # TODO: load this from type_map
        - [Tobacco_use, Substance_use_status] 
        - [Substance_use_status, Smoking_type]
        - [Substance_use_status, Smoking_freq_ppd] 
        - [Substance_use_status, Smoking_freq_py] 
        - [Substance_use_status, Smoking_freq_qy] 
        - [Substance_use_status, Smoking_freq_sy]
        - [Substance_use_status, Smoking_freq_other] 
        - [Alcohol_use, Substance_use_status]
        - [Substance_use_status, Alcohol_freq] 
        - [Substance_use_status, Alcohol_type] 
        - [Substance_use_status, Alcohol_other] 
        - [Drug_use, Substance_use_status]
        - [Substance_use_status, Drug_freq] 
        - [Substance_use_status, Drug_type]
        - [Substance_use_status, Drug_other] 
        - [Sex_act, Sdoh_status]
        - [Sex_act, Partner] 
        - [Sex_act, Protection] 
        - [Sex_act, Sex_act_other] 
        - [Occupation, Employment_status]
        - [Occupation, Employment_location] 
        - [Gender, Sdoh_status]
        - [Social_cohesion, Social_method] 
        - [Social_method, Sdoh_status]
        - [Physical_act, Sdoh_status] 
        - [Physical_act, Sdoh_freq] 
        - [Living_supply, Sdoh_status] 
        - [Abuse, Sdoh_status]
        - [Transportation, Sdoh_status] 
        - [Health_literacy, Sdoh_status]
        - [Financial_constrain, Sdoh_status] 
        - [Social_cohesion, Sdoh_status]
        - [Social_cohesion, Sdoh_freq] 
        - [Gender, Sdoh_status] 
        - [Race, Sdoh_status] 
        - [Ethnicity, Sdoh_status]
        - [Living_Condition, Sdoh_status]
    params:
      model_type: bert
      # new_model_dir: /home/dparedespardo/project/SDoH/pipeline/execution/model/bert/
      new_model_dir: /models/bert/
      do_lower_case: True
      eval_batch_size: 4
      max_seq_length: 512
      data_format_mode: 0
      data_file_header: True
      num_core: 1
      non_relation_label: NonRel
      classification_mode: bin
      log_lvl: w

  csv_output_params:
    force_rewrite: True # remove old csv if True
    ouput_file: output.csv

negation_inference:
  dependency_tree:
  - [brat_neg,tsv]
  - [tsv,brat]
  - [tsv,bio_init]
  - [tsv,encoded_text]
  - [bio_init, encoded_text]
  - [bio_init, raw_text]
  - [encoded_text, raw_text]
  root_dir: /data/datasets/shared_data_2/pipeline_dev_test_regex
  raw_data_dir: /data/datasets/dparedes/project/LungRADS_nodules/sample_notes_sc_sz/radiology_reports

  sent_tokenizer:
    _class: SentenceBoundaryDetection
    params:
      deid_pattern: \[\*\*|\*\*\]

  negation_model:
    _class:
    preprocess:
      entity_label: nodule
      EN1_START: "[s]"
      EN1_END: "[e]"
      NEG_REL: not-negated
    postprocess:
      keep_cat: [negated]
    params:
      model_type: bert
      new_model_dir: /home/jameshuang/Projects/NLP_annotation/fine_tuned_negation/mimiciii_bert-base-uncased_10e_128b/lr_1e-4_max_seq_length_256_batch_size_4/model
      do_lower_case: True
      eval_batch_size: 4
      max_seq_length: 256
      data_format_mode: 0
      data_file_header: True
      num_core: 16
      non_relation_label: NonRel
      classification_scheme: 1
      do_predict: True
      seed: 13
      log_lvl: i
      
lungrads_pipeline:  # Generate output csv from raw text
  pipeline: lungrads
  dependency_tree:
    - [csv_output, brat]
    - [csv_output, brat_re]
    - [csv_output, brat_neg]
    - [csv_output, brat_unit]
    - [csv_output, brat_regex]
    - [csv_output, encoded_text]
    - [brat_unit, encoded_text]
    - [brat_unit, brat]
    - [brat_regex, encoded_text]
    - [brat_regex, brat]
    - [brat_re,tsv]
    - [brat_neg,tsv]
    - [tsv,brat]
    - [tsv,bio_init]
    - [tsv,encoded_text]
    - [brat,bio_init]
    - [brat,encoded_text]
    - [bio_init, encoded_text]
    - [bio_init, raw_text]
    - [encoded_text, raw_text]
  # root_dir: /data/datasets/shared_data_2/IRB201901754_lungrads
  root_dir: /data/datasets/shared_data_2/pipeline_dev_test_lungrads
  raw_data_dir: /data/datasets/shared_data_2/pipeline_dev_test_lungrads/raw_text/
  # root_dir: /data/datasets/shared_data_2/2022_IRB201901754_LDCT_IDR_data/radiology_reports/
  # raw_data_dir: /data/datasets/shared_data_2/2022_IRB201901754_LDCT_IDR_data/radiology_reports/raw_text/
  # TODO: specify model parameters here

  sent_tokenizer:
    _class: SentenceBoundaryDetection
    params:
      deid_pattern: \[\*\*|\*\*\]

  ner_model:
    _class:
    params:
      model_type: roberta
      pretrained_model: /home/jameshuang/Projects/NLP_annotation/fine_tuned_ner/mimiciii_roberta-base_10e_128b_bz=8
      do_lower_case: True
      eval_batch_size: 8
      max_seq_length: 128
      data_has_offset_information: True
      use_bio: False
        
  relation_model:
    _class:
    preprocess:
      CUTOFF: 1
      EN1_START: "[s1]"
      EN1_END: "[e1]"
      EN2_START: "[s2]"
      EN2_END: "[e2]"
      NEG_REL: NonRel
      valid_comb: # TODO: load this from type_map
        - [nodule, texture]
        - [nodule, size]
        - [nodule, laterality]
        - [nodule, site]
        - [nodule, course]
        - [nodule, shape]  
    params:
      model_type: albert
      new_model_dir: /data/datasets/alexgre/archive/from_wu_server/experiements/2020_lungrads/relation_extraction/models/RE_bin_albert_albert-base-v2_aio_cs2_0_th1_5_4
      do_lower_case: True
      eval_batch_size: 128
      max_seq_length: 512
      data_format_mode: 0
      data_file_header: True
      num_core: 1
      non_relation_label: NonRel
      classification_mode: bin
      type_map: /data/datasets/alexgre/archive/from_wu_server/experiements/2020_lungrads/re_all/mappings.pkl
      log_lvl: w

  negation_model:
    _class:
    preprocess:
      entity_label: nodule
      EN1_START: "[s]"
      EN1_END: "[e]"
      NEG_REL: not-negated
    postprocess:
      keep_cat: [negated]
    params:
      model_type: bert
      new_model_dir: /home/jameshuang/Projects/NLP_annotation/fine_tuned_negation/mimiciii_bert-base-uncased_10e_128b/lr_1e-4_max_seq_length_256_batch_size_4/model
      do_lower_case: True
      eval_batch_size: 4
      max_seq_length: 256
      data_format_mode: 0
      data_file_header: True
      num_core: 16
      non_relation_label: NonRel
      classification_scheme: 1
      do_predict: True
      seed: 13
      log_lvl: i

  unit_extraction_model:
    _class:
    postprocess:
      normalize: mm

  regex_params:
    - parent_label: texture
      parent_text: '\bsolid\b'
      label: solid_size
      text: 
      - regex: '(solid (?:portion|component|part)s?)\s+(?:(?:[a-z]+\s)+)((?:\d+(?:\.\d+)?)(?:(?:\s*x\s*(?:\d+(?:\.\d+)?))*)\s*(?:cm|mm))'
        parent_text_group: 1
        text_group: 2
        exclude:
        - text: 'and'
          except: 'and measur' 
        - text: 'with'
      - regex: '((?:\d+(?:\.\d+)?)(?:(?:\s*x\s*(?:\d+(?:\.\d+)?))*)\s*(?:cm|mm))\s*(?:(?:[a-z]+\s)*)(solid (?:portion|component|part)s?)'
        parent_text_group: 2
        text_group: 1
        exclude:
        - text: 'and'
        - text: 'with'
    - parent_label: texture
      parent_text: '(?<!non)(?<!not)(?<!-)(?<!- )calcifi(?:cation|ed)'
      label: calcification_type
      text: 
      - regex: '(?<!-)(?<!\s) (total(?:ly|) calcifi(?:cation|ed))'
      - regex: '(?<!-)(?<!\s) (complete(?:ly|) calcifi(?:cation|ed))'
      - regex: '(?<!-)(?<!\s) (central(?:ly|) calcifi(?:cation|ed))'
      - regex: '(?<!-)(?<!\s) (popcorn calcification)'
      - regex: '(?<!-)(?<!\s) (calcifi(?:cation|ed) in concentric rings)'
      - regex: '(?<!-)(?<!\s) (fat-containing nodule(?:s|))'

  csv_output_params:
    force_rewrite: True # remove old csv if True
    ouput_file: output.csv